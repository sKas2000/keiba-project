#!/usr/bin/env python3
"""
JRAå…¬å¼ã‚µã‚¤ãƒˆ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ v1.4
=================================
v1.2: å˜å‹ãƒ»è¤‡å‹ãƒ»é¦¬é€£ãƒ»ãƒ¯ã‚¤ãƒ‰å–å¾—æˆåŠŸ
v1.3: ãƒ¬ãƒ¼ã‚¹æƒ…å ±è‡ªå‹•å–å¾—ï¼ˆè·é›¢ãƒ»ã‚°ãƒ¬ãƒ¼ãƒ‰ä¸€éƒ¨å¤±æ•—ï¼‰
v1.4: ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’ DIV.race_title ã‹ã‚‰æ­£ç¢ºã«å–å¾—
      3é€£è¤‡ï¼ˆäºŒé‡ä¸‰è§’è¡Œåˆ—ï¼‰ãƒ‘ãƒ¼ã‚¹è¿½åŠ 
      é¦¬å˜ï¼ˆæ­£æ–¹è¡Œåˆ—ï¼‰ãƒ‘ãƒ¼ã‚¹è¿½åŠ 

ä½¿ã„æ–¹:
  python jra_scraper.py
"""

VERSION = "1.4"

import asyncio
import json
import re
import sys
from datetime import datetime
from pathlib import Path

try:
    from playwright.async_api import async_playwright
except ImportError:
    print("Playwright ãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™:")
    print("  pip install playwright")
    print("  playwright install chromium")
    sys.exit(1)


# ============================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ============================================================

def safe_float(text: str) -> float:
    try:
        return float(text.strip().replace(",", ""))
    except (ValueError, AttributeError):
        return 0.0


def parse_odds_range(text: str) -> float:
    """'2.4-6.1' â†’ ä¸­å¤®å€¤ 4.25"""
    text = text.strip()
    m = re.match(r"([\d.]+)\s*[-ï½]\s*([\d.]+)", text)
    if m:
        return round((float(m.group(1)) + float(m.group(2))) / 2, 1)
    return safe_float(text)


def parse_odds_range_low(text: str) -> float:
    """'2.4-6.1' â†’ ä¸‹é™ 2.4"""
    text = text.strip()
    m = re.match(r"([\d.]+)\s*[-ï½]\s*([\d.]+)", text)
    if m:
        return float(m.group(1))
    return safe_float(text)


def extract_venue(meeting_text: str) -> str:
    """'1å›æ±äº¬5æ—¥' â†’ 'æ±äº¬'"""
    m = re.search(r"\d+å›(.+?)\d+æ—¥", meeting_text)
    return m.group(1) if m else ""


# ============================================================
# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼æœ¬ä½“
# ============================================================

class JRAScraper:
    def __init__(self, headless=False, debug=True):
        self.headless = headless
        self.debug = debug
        self.pw = None
        self.browser = None
        self.ctx = None
        self.page = None

    def log(self, msg):
        if self.debug:
            print(f"  [DEBUG] {msg}")

    async def start(self):
        self.pw = await async_playwright().start()
        self.browser = await self.pw.chromium.launch(headless=self.headless)
        self.ctx = await self.browser.new_context(
            viewport={"width": 1280, "height": 900},
            locale="ja-JP",
        )
        self.page = await self.ctx.new_page()
        self.page.set_default_timeout(15000)

    async def close(self):
        if self.ctx:
            await self.ctx.close()
        if self.browser:
            await self.browser.close()
        if self.pw:
            await self.pw.stop()

    # ----------------------------------------------------------
    # ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
    # ----------------------------------------------------------

    async def goto_odds_top(self):
        await self.page.goto("https://www.jra.go.jp/", wait_until="domcontentloaded")
        await asyncio.sleep(1)
        await self.page.get_by_role("link", name="ã‚ªãƒƒã‚º").first.click()
        await self.page.wait_for_load_state("domcontentloaded")
        await asyncio.sleep(1)

        meetings = []
        links = await self.page.locator("a").all()
        for link in links:
            text = await link.text_content()
            if text and "å›" in text and "æ—¥" in text:
                meetings.append({"text": text.strip(), "element": link})
        return meetings

    async def select_meeting(self, el):
        await el.click()
        await self.page.wait_for_load_state("domcontentloaded")
        await asyncio.sleep(1)

    async def select_race(self, num):
        await self.page.get_by_role("link", name=f"{num}ãƒ¬ãƒ¼ã‚¹").first.click()
        await self.page.wait_for_load_state("domcontentloaded")
        await asyncio.sleep(1)

    async def click_tab(self, name):
        await self.page.get_by_role("link", name=name).first.click()
        await self.page.wait_for_load_state("domcontentloaded")
        await asyncio.sleep(1)

    # ----------------------------------------------------------
    # ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã®è‡ªå‹•å–å¾—ï¼ˆv1.4: DIV.race_title ã‹ã‚‰æ­£ç¢ºã«å–å¾—ï¼‰
    # ----------------------------------------------------------

    async def scrape_race_info(self, meeting_text: str, race_num: int) -> dict:
        info = {
            "venue": extract_venue(meeting_text),
            "race_number": race_num,
            "name": "",
            "grade": "",
            "surface": "",
            "distance": 0,
            "direction": "",
        }

        self.log("ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’è‡ªå‹•å–å¾—ä¸­...")

        # 1) SPAN.race_name â†’ ãƒ¬ãƒ¼ã‚¹å
        try:
            el = self.page.locator("span.race_name").first
            text = await el.text_content()
            if text:
                info["name"] = text.strip()
                self.log(f"  ãƒ¬ãƒ¼ã‚¹å: {info['name']}")
        except Exception:
            pass

        # 2) DIV.race_title â†’ è·é›¢ãƒ»é¦¬å ´ãƒ»å›ã‚Šãƒ»ã‚°ãƒ¬ãƒ¼ãƒ‰
        try:
            el = self.page.locator("div.race_title").first
            title = await el.text_content()
            if title:
                title = title.strip()
                self.log(f"  race_title: {title}")

                # è·é›¢: "1,400ãƒ¡ãƒ¼ãƒˆãƒ«" or "2000ãƒ¡ãƒ¼ãƒˆãƒ«"
                m = re.search(r"([\d,]+)\s*ãƒ¡ãƒ¼ãƒˆãƒ«", title)
                if m:
                    info["distance"] = int(m.group(1).replace(",", ""))
                    self.log(f"  è·é›¢: {info['distance']}m")

                # é¦¬å ´ãƒ»å›ã‚Š: "ï¼ˆãƒ€ãƒ¼ãƒˆãƒ»å·¦ï¼‰" or "ï¼ˆèŠãƒ»å³ å¤–ï¼‰"
                m = re.search(r"ï¼ˆ(èŠ|ãƒ€ãƒ¼ãƒˆ)ãƒ»(å³|å·¦)\s*(å¤–|å†…)?ï¼‰", title)
                if m:
                    info["surface"] = m.group(1)
                    info["direction"] = m.group(2) + (m.group(3) or "")
                    self.log(f"  é¦¬å ´: {info['surface']} {info['direction']}")

                # ã‚°ãƒ¬ãƒ¼ãƒ‰ï¼ˆrace_title å†…ã«é™å®šã—ã¦æ¤œç´¢ï¼‰
                grade_patterns = [
                    (r"Gâ… |ï¼ˆGâ… ï¼‰", "G1"),
                    (r"Gâ…¡|ï¼ˆGâ…¡ï¼‰", "G2"),
                    (r"Gâ…¢|ï¼ˆGâ…¢ï¼‰", "G3"),
                    (r"ãƒªã‚¹ãƒ†ãƒƒãƒ‰", "L"),
                    (r"ã‚ªãƒ¼ãƒ—ãƒ³", "OP"),
                    (r"3å‹ã‚¯ãƒ©ã‚¹", "3å‹"),
                    (r"2å‹ã‚¯ãƒ©ã‚¹", "2å‹"),
                    (r"1å‹ã‚¯ãƒ©ã‚¹", "1å‹"),
                    (r"æœªå‹åˆ©", "æœªå‹åˆ©"),
                    (r"æ–°é¦¬", "æ–°é¦¬"),
                ]
                for pattern, label in grade_patterns:
                    if re.search(pattern, title):
                        info["grade"] = label
                        self.log(f"  ã‚°ãƒ¬ãƒ¼ãƒ‰: {label}")
                        break
        except Exception as e:
            self.log(f"  race_titleå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

        # 3) ãƒ¬ãƒ¼ã‚¹åãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆh2ã‹ã‚‰ï¼‰
        if not info["name"]:
            try:
                h2s = await self.page.locator("h2").all()
                for h2 in h2s:
                    text = await h2.text_content()
                    if text and any(kw in text for kw in
                                    ["ç‰¹åˆ¥", "ã‚¹ãƒ†ãƒ¼ã‚¯ã‚¹", "è³", "ã‚«ãƒƒãƒ—",
                                     "æœªå‹åˆ©", "æ–°é¦¬", "1å‹", "2å‹", "3å‹"]):
                        info["name"] = text.strip()
                        self.log(f"  ãƒ¬ãƒ¼ã‚¹å(h2): {info['name']}")
                        break
            except Exception:
                pass

        # æœªæ¤œå‡ºã‚µãƒãƒªãƒ¼
        missing = []
        if not info["name"]:
            missing.append("ãƒ¬ãƒ¼ã‚¹å")
        if not info["surface"]:
            missing.append("é¦¬å ´")
        if not info["distance"]:
            missing.append("è·é›¢")
        if not info["grade"]:
            missing.append("ã‚°ãƒ¬ãƒ¼ãƒ‰")
        if missing:
            self.log(f"  âš ï¸ æœªæ¤œå‡º: {', '.join(missing)}")
        else:
            self.log("  âœ… å…¨é …ç›®å–å¾—æˆåŠŸ")

        return info

    # ----------------------------------------------------------
    # å˜å‹ãƒ»è¤‡å‹
    # ----------------------------------------------------------

    async def parse_win_place(self):
        horses = []
        await self.click_tab("å˜å‹ãƒ»è¤‡å‹")

        tables = await self.page.locator("table").all()
        self.log(f"å˜å‹ãƒ»è¤‡å‹ãƒ†ãƒ¼ãƒ–ãƒ«æ•°: {len(tables)}")

        for ti, table in enumerate(tables):
            ths = await table.locator("th").all()
            headers = []
            for th in ths:
                t = await th.text_content()
                headers.append(t.strip() if t else "")

            if not any("é¦¬ç•ª" in h for h in headers):
                continue

            self.log(f"  â˜…é¦¬ç•ªãƒ†ãƒ¼ãƒ–ãƒ«ç™ºè¦‹ (ãƒ†ãƒ¼ãƒ–ãƒ«{ti})")

            rows = await table.locator("tbody tr").all()
            if not rows:
                rows = await table.locator("tr").all()

            for row in rows:
                cells = await row.locator("td").all()
                if len(cells) < 4:
                    continue

                ct = []
                for cell in cells:
                    t = await cell.text_content()
                    ct.append(t.strip() if t else "")

                # é¦¬ç•ªã‚»ãƒ«ã‚’æ¢ã™
                num_idx = -1
                for i, t in enumerate(ct):
                    if re.match(r"^\d{1,2}$", t) and 1 <= int(t) <= 18:
                        num_idx = i
                        break

                if num_idx < 0:
                    continue

                horse_num = int(ct[num_idx])
                idx = num_idx + 1

                def get():
                    nonlocal idx
                    val = ct[idx] if idx < len(ct) else ""
                    idx += 1
                    return val

                name = get()
                odds_win = safe_float(get())
                odds_place_str = get()
                odds_place = parse_odds_range_low(odds_place_str)
                sex_age = get()
                weight = get()
                load = safe_float(get())
                jockey = get()
                jockey = re.sub(r"[â–²â–³â˜†â—‡]", "", jockey).strip()

                horses.append({
                    "num": horse_num,
                    "name": name,
                    "odds_win": odds_win,
                    "odds_place": odds_place,
                    "sex_age": sex_age,
                    "weight": weight,
                    "load_weight": load,
                    "jockey": jockey,
                })

            if horses:
                break

        return horses

    # ----------------------------------------------------------
    # ä¸‰è§’è¡Œåˆ—ãƒ‘ãƒ¼ã‚µãƒ¼ï¼ˆé¦¬é€£ãƒ»ãƒ¯ã‚¤ãƒ‰å…±é€šï¼‰
    # ----------------------------------------------------------

    async def _get_numeric_tables(self):
        """ãƒ˜ãƒƒãƒ€ãƒ¼ãŒå…¨ã¦æ•°å­—ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é †ç•ªã«è¿”ã™"""
        tables = await self.page.locator("table").all()
        result = []
        for table in tables:
            ths = await table.locator("th").all()
            headers = []
            for th in ths:
                t = await th.text_content()
                headers.append(t.strip() if t else "")
            if not headers:
                continue
            if all(re.match(r"^\d{1,2}$", h) for h in headers):
                # è¡Œãƒ‡ãƒ¼ã‚¿å–å¾—
                rows_data = []
                rows = await table.locator("tr").all()
                for row in rows:
                    cells = await row.locator("td").all()
                    if not cells:
                        continue
                    ct = []
                    for cell in cells:
                        t = await cell.text_content()
                        ct.append(t.strip() if t else "")
                    rows_data.append(ct)
                result.append({
                    "headers": [int(h) for h in headers],
                    "rows": rows_data,
                })
        return result

    async def parse_triangle_odds(self, tab_name, is_range=False):
        """é¦¬é€£ãƒ»ãƒ¯ã‚¤ãƒ‰ã®ä¸‰è§’è¡Œåˆ—ãƒ‘ãƒ¼ã‚¹"""
        results = []
        await self.click_tab(tab_name)

        num_tables = await self._get_numeric_tables()
        self.log(f"{tab_name}: æ•°å€¤ãƒ†ãƒ¼ãƒ–ãƒ« {len(num_tables)}å€‹")

        for tbl in num_tables:
            headers = tbl["headers"]
            base = headers[0] - 1
            if base < 1:
                continue

            for pi, row in enumerate(tbl["rows"]):
                if pi >= len(headers):
                    break
                partner = headers[pi]
                if not row or not row[0]:
                    continue
                odds = parse_odds_range(row[0]) if is_range else safe_float(row[0])
                if odds > 0:
                    results.append({
                        "combo": sorted([base, partner]),
                        "odds": odds,
                    })

        return results

    # ----------------------------------------------------------
    # 3é€£è¤‡ãƒ‘ãƒ¼ã‚µãƒ¼ï¼ˆv1.4: äºŒé‡ä¸‰è§’è¡Œåˆ—ï¼‰
    # ----------------------------------------------------------

    async def parse_trio(self):
        """
        3é€£è¤‡ã®æ§‹é€ :
          Né ­ã®å ´åˆ C(N-1,2) å€‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã€‚
          ãƒ†ãƒ¼ãƒ–ãƒ«é †åº: (i,j) ã‚’ i=1..N-1, j=i+1..N-1 ã§åˆ—æŒ™ã€‚
          å„ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ˜ãƒƒãƒ€ãƒ¼ = [j+1, j+2, ..., N] = 3é ­ç›®ã®é¦¬ç•ªã€‚
          å„è¡Œã®ã‚ªãƒƒã‚º = 3é€£è¤‡ {i, j, k} ã®é…å½“ã€‚
        """
        results = []
        try:
            await self.click_tab("3é€£è¤‡")

            num_tables = await self._get_numeric_tables()
            n_tables = len(num_tables)
            self.log(f"3é€£è¤‡: æ•°å€¤ãƒ†ãƒ¼ãƒ–ãƒ« {n_tables}å€‹")

            if n_tables == 0:
                return results

            # é ­æ•°Nã‚’æ¨å®š: æœ€åˆã®ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ˜ãƒƒãƒ€ãƒ¼æ•° = N-2
            N = len(num_tables[0]["headers"]) + 2
            expected = (N - 1) * (N - 2) // 2
            self.log(f"3é€£è¤‡: æ¨å®šé ­æ•° N={N}, æœŸå¾…ãƒ†ãƒ¼ãƒ–ãƒ«æ•°={expected}, å®Ÿéš›={n_tables}")

            # ãƒšã‚¢(i,j)ã®é †åºã‚’äº‹å‰è¨ˆç®—
            pairs = []
            for i in range(1, N):
                for j in range(i + 1, N):
                    pairs.append((i, j))

            # ãƒ†ãƒ¼ãƒ–ãƒ«ã¨ãƒšã‚¢ã‚’å¯¾å¿œä»˜ã‘
            for t_idx, (i, j) in enumerate(pairs):
                if t_idx >= n_tables:
                    break

                tbl = num_tables[t_idx]
                headers = tbl["headers"]

                for r_idx, row in enumerate(tbl["rows"]):
                    if r_idx >= len(headers):
                        break
                    k = headers[r_idx]
                    if not row or not row[0]:
                        continue
                    odds = safe_float(row[0])
                    if odds > 0:
                        results.append({
                            "combo": sorted([i, j, k]),
                            "odds": odds,
                        })

            self.log(f"3é€£è¤‡: {len(results)}çµ„å–å¾—")

        except Exception as e:
            self.log(f"3é€£è¤‡ã‚¨ãƒ©ãƒ¼: {e}")

        return results

    # ----------------------------------------------------------
    # é¦¬å˜ãƒ‘ãƒ¼ã‚µãƒ¼ï¼ˆv1.4: æ­£æ–¹è¡Œåˆ—ï¼‰
    # ----------------------------------------------------------

    async def parse_exacta(self):
        """
        é¦¬å˜ã®æ§‹é€ :
          Nå€‹ã®ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆå„Nè¡ŒÃ—1ã‚»ãƒ«ï¼‰ã€‚
          ãƒ†ãƒ¼ãƒ–ãƒ«t = 1ç€é¦¬ t+1ã€‚
          è¡Œr = 2ç€é¦¬ r+1ã€‚
          å¯¾è§’ç·šï¼ˆåŒé¦¬ï¼‰ã¯ç©ºã‚»ãƒ«ã€‚
        """
        results = []
        try:
            await self.click_tab("é¦¬å˜")

            num_tables = await self._get_numeric_tables()
            self.log(f"é¦¬å˜: æ•°å€¤ãƒ†ãƒ¼ãƒ–ãƒ« {len(num_tables)}å€‹")

            for t_idx, tbl in enumerate(num_tables):
                first = t_idx + 1  # 1ç€é¦¬ç•ª

                for r_idx, row in enumerate(tbl["rows"]):
                    second = r_idx + 1  # 2ç€é¦¬ç•ª
                    if first == second:
                        continue
                    if not row or not row[0]:
                        continue
                    odds = safe_float(row[0])
                    if odds > 0:
                        results.append({
                            "combo": [first, second],  # é †åºã‚ã‚Š [1ç€, 2ç€]
                            "odds": odds,
                        })

            self.log(f"é¦¬å˜: {len(results)}çµ„å–å¾—")

        except Exception as e:
            self.log(f"é¦¬å˜ã‚¨ãƒ©ãƒ¼: {e}")

        return results


# ============================================================
# input.json ç”Ÿæˆ
# ============================================================

def build_json(scraped, race_info):
    horses = []
    for h in scraped.get("horses", []):
        horses.append({
            "num": h["num"],
            "name": h["name"],
            "score": 0,
            "score_breakdown": {
                "ability": 0, "jockey": 0, "fitness": 0,
                "form": 0, "other": 0,
            },
            "odds_win": h["odds_win"],
            "odds_place": h["odds_place"],
            "jockey": h.get("jockey", ""),
            "sex_age": h.get("sex_age", ""),
            "weight": h.get("weight", ""),
            "load_weight": h.get("load_weight", 0),
            "note": "",
        })

    grade = race_info.get("grade", "")
    defaults = {
        "G1": (8, 10000), "G2": (8, 5000), "G3": (10, 3000),
        "L": (10, 3000), "OP": (10, 3000),
        "3å‹": (10, 1500), "2å‹": (10, 1500),
        "1å‹": (12, 1500), "æœªå‹åˆ©": (12, 1500), "æ–°é¦¬": (14, 1500),
    }
    temp, budget = defaults.get(grade, (10, 1500))

    return {
        "race": {
            "date": datetime.now().strftime("%Y-%m-%d"),
            "venue": race_info.get("venue", ""),
            "race_number": race_info.get("race_number", 0),
            "name": race_info.get("name", ""),
            "grade": grade,
            "surface": race_info.get("surface", ""),
            "distance": race_info.get("distance", 0),
            "direction": race_info.get("direction", ""),
            "entries": len(horses),
            "weather": "",
            "track_condition": "",
        },
        "parameters": {
            "temperature": temp,
            "budget": budget,
            "top_n": 6,
        },
        "horses": horses,
        "combo_odds": {
            "exacta": scraped.get("exacta", []),
            "quinella": scraped.get("quinella", []),
            "wide": scraped.get("wide", []),
            "trio": scraped.get("trio", []),
        },
    }


# ============================================================
# ãƒ¡ã‚¤ãƒ³
# ============================================================

async def main():
    print()
    print("=" * 60)
    print(f"  ğŸ‡ JRA ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ v{VERSION}")
    print("=" * 60)
    print()

    scraper = JRAScraper(headless=False, debug=True)

    try:
        await scraper.start()

        # --- é–‹å‚¬é¸æŠ ---
        print("ğŸŒ JRAå…¬å¼ã‚µã‚¤ãƒˆã«æ¥ç¶šä¸­...")
        meetings = await scraper.goto_odds_top()

        if not meetings:
            print("âŒ é–‹å‚¬æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return

        print(f"\nğŸ“… é–‹å‚¬ä¸€è¦§ ({len(meetings)}ä»¶):")
        for i, m in enumerate(meetings):
            print(f"  [{i+1}] {m['text']}")

        while True:
            c = input(f"\né–‹å‚¬ã‚’é¸æŠ (1-{len(meetings)}): ").strip()
            if c.isdigit() and 1 <= int(c) <= len(meetings):
                mi = int(c) - 1
                break
            print("  ç„¡åŠ¹")

        meeting_text = meetings[mi]["text"]
        await scraper.select_meeting(meetings[mi]["element"])

        # --- ãƒ¬ãƒ¼ã‚¹é¸æŠ ---
        while True:
            c = input("ãƒ¬ãƒ¼ã‚¹ç•ªå· (1-12): ").strip()
            if c.isdigit() and 1 <= int(c) <= 12:
                rn = int(c)
                break
            print("  ç„¡åŠ¹")

        print(f"\nğŸ‡ {rn}R ã‚’é¸æŠä¸­...")
        await scraper.select_race(rn)

        # === ãƒ¬ãƒ¼ã‚¹æƒ…å ± ===
        print("\nğŸ” ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’è‡ªå‹•å–å¾—ä¸­...")
        race_info = await scraper.scrape_race_info(meeting_text, rn)

        venue = race_info["venue"]
        name = race_info["name"]
        surface = race_info["surface"]
        distance = race_info["distance"]
        direction = race_info["direction"]
        grade = race_info["grade"]

        print(f"\nğŸ“ è‡ªå‹•å–å¾—çµæœ:")
        print(f"  ç«¶é¦¬å ´:   {venue or 'ï¼ˆæœªæ¤œå‡ºï¼‰'}")
        print(f"  ãƒ¬ãƒ¼ã‚¹å: {name or 'ï¼ˆæœªæ¤œå‡ºï¼‰'}")
        print(f"  é¦¬å ´:     {surface or 'ï¼ˆæœªæ¤œå‡ºï¼‰'} {direction}")
        print(f"  è·é›¢:     {distance or 'ï¼ˆæœªæ¤œå‡ºï¼‰'}{'m' if distance else ''}")
        print(f"  ã‚°ãƒ¬ãƒ¼ãƒ‰: {grade or 'ï¼ˆæœªæ¤œå‡ºï¼‰'}")

        # æœªæ¤œå‡ºé …ç›®ã®ã¿æ‰‹å‹•å…¥åŠ›
        if not venue:
            venue = input("\n  â†’ ç«¶é¦¬å ´ã‚’å…¥åŠ› (ä¾‹: æ±äº¬): ").strip()
            race_info["venue"] = venue
        if not name:
            name = input(f"  â†’ ãƒ¬ãƒ¼ã‚¹å (ä¾‹: {rn}R): ").strip() or f"{rn}R"
            race_info["name"] = name
        if not surface:
            surface = input("  â†’ é¦¬å ´ (èŠ/ãƒ€ãƒ¼ãƒˆ): ").strip()
            race_info["surface"] = surface
        if not distance:
            d = input("  â†’ è·é›¢ (ä¾‹: 1400): ").strip()
            race_info["distance"] = int(d) if d.isdigit() else 0
        if not direction:
            direction = input("  â†’ å›ã‚Š (å³/å·¦): ").strip()
            race_info["direction"] = direction
        if not grade:
            grade = input("  â†’ ã‚°ãƒ¬ãƒ¼ãƒ‰ (G1/G2/G3/OP/3å‹/2å‹/1å‹/æœªå‹åˆ©/æ–°é¦¬): ").strip()
            race_info["grade"] = grade

        confirm = input("\nâœ… å–å¾—é–‹å§‹ (Enter / n ã§ã‚­ãƒ£ãƒ³ã‚»ãƒ«): ").strip()
        if confirm.lower() == "n":
            print("ã‚­ãƒ£ãƒ³ã‚»ãƒ«")
            return

        # === ã‚ªãƒƒã‚ºå–å¾— ===
        print("\nğŸ“‹ å˜å‹ãƒ»è¤‡å‹ã‚’å–å¾—ä¸­...")
        horses = await scraper.parse_win_place()
        print(f"  â†’ {len(horses)}é ­")
        for h in horses:
            print(f"    {h['num']:2d}ç•ª {h['name']}  "
                  f"å˜å‹{h['odds_win']:.1f}  è¤‡å‹{h['odds_place']:.1f}  "
                  f"{h['jockey']}")

        print("\nğŸ“‹ é¦¬é€£ã‚’å–å¾—ä¸­...")
        quinella = await scraper.parse_triangle_odds("é¦¬é€£", is_range=False)
        print(f"  â†’ {len(quinella)}çµ„")

        print("\nğŸ“‹ ãƒ¯ã‚¤ãƒ‰ã‚’å–å¾—ä¸­...")
        wide = await scraper.parse_triangle_odds("ãƒ¯ã‚¤ãƒ‰", is_range=True)
        print(f"  â†’ {len(wide)}çµ„")

        print("\nğŸ“‹ é¦¬å˜ã‚’å–å¾—ä¸­...")
        exacta = await scraper.parse_exacta()
        print(f"  â†’ {len(exacta)}çµ„")

        print("\nğŸ“‹ 3é€£è¤‡ã‚’å–å¾—ä¸­...")
        trio = await scraper.parse_trio()
        print(f"  â†’ {len(trio)}çµ„")

        scraped = {
            "horses": horses,
            "exacta": exacta,
            "quinella": quinella,
            "wide": wide,
            "trio": trio,
        }

        # === JSONä¿å­˜ ===
        out = build_json(scraped, race_info)

        date_str = datetime.now().strftime("%Y%m%d")
        safe_name = re.sub(r'[\\/:*?"<>|\s]', '_', name or f"{rn}R")
        fname = f"{date_str}_{venue}_{safe_name}_input.json"

        script_dir = Path(__file__).resolve().parent
        out_dir = script_dir.parent / "data" / "races"
        out_dir.mkdir(parents=True, exist_ok=True)
        out_path = out_dir / fname

        with open(out_path, "w", encoding="utf-8") as f:
            json.dump(out, f, ensure_ascii=False, indent=2)

        # === ã‚µãƒãƒªãƒ¼ ===
        n_horses = len(horses)
        # æœŸå¾…çµ„æ•°
        expected_q = n_horses * (n_horses - 1) // 2
        expected_e = n_horses * (n_horses - 1)
        expected_t = (n_horses * (n_horses - 1) * (n_horses - 2)) // 6

        print(f"\n{'=' * 60}")
        print(f"  âœ… ä¿å­˜å®Œäº†: {out_path}")
        print(f"{'=' * 60}")
        print(f"\nğŸ“Š ã‚µãƒãƒªãƒ¼:")
        print(f"  {venue}{rn}R {name}")
        print(f"  {surface}{direction} {race_info.get('distance', 0)}m  {grade}")
        print(f"  å‡ºèµ°é¦¬: {n_horses}é ­")
        print(f"  é¦¬é€£:   {len(quinella)}/{expected_q}çµ„")
        print(f"  ãƒ¯ã‚¤ãƒ‰: {len(wide)}/{expected_q}çµ„")
        print(f"  é¦¬å˜:   {len(exacta)}/{expected_e}çµ„")
        print(f"  3é€£è¤‡:  {len(trio)}/{expected_t}çµ„")
        print(f"\nğŸ’¡ Claudeã«è©•ä¾¡ç‚¹ã‚’ä¾é ¼ã—ã¦ãã ã•ã„")

    except KeyboardInterrupt:
        print("\nâš ï¸ ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
    finally:
        await scraper.close()


if __name__ == "__main__":
    asyncio.run(main())
